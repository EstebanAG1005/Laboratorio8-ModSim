{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install simpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simpy\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tasa de solicitudes por segundo\n",
    "LAMBDA = 2400 / 60  # Convertimos las solicitudes por minuto a solicitudes por segundo\n",
    "\n",
    "# Duración de la simulación en segundos (1 hora)\n",
    "SIMULATION_TIME = 3600  \n",
    "\n",
    "# Proveedor 1\n",
    "MU_1 = 100  # Tasa de servicio de 100 solicitudes por segundo\n",
    "\n",
    "# Proveedor 2\n",
    "MU_2 = 10    # Tasa de servicio de 10 solicitudes por segundo\n",
    "SERVERS_2 = 10  # Número de servidores\n",
    "\n",
    "# Variables para estadísticas para Proveedor 1 y Proveedor 2\n",
    "total_requests_1 = total_requests_2 = 0\n",
    "total_time_in_queue_1 = total_time_in_queue_2 = 0\n",
    "total_time_of_service_1 = total_time_of_service_2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request(env, mu, server, provider):\n",
    "    global total_time_in_queue_1, total_time_of_service_1, total_time_in_queue_2, total_time_of_service_2\n",
    "    \n",
    "    arrival_time = env.now\n",
    "    with server.request() as req:\n",
    "        yield req\n",
    "        wait_time = env.now - arrival_time\n",
    "        \n",
    "        if provider == 1:\n",
    "            total_time_in_queue_1 += wait_time\n",
    "        elif provider == 2:\n",
    "            total_time_in_queue_2 += wait_time\n",
    "        \n",
    "        # El servicio se modela con una distribución exponencial\n",
    "        yield env.timeout(random.expovariate(mu))\n",
    "        \n",
    "        if provider == 1:\n",
    "            total_time_of_service_1 += env.now - arrival_time\n",
    "        elif provider == 2:\n",
    "            total_time_of_service_2 += env.now - arrival_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_generator(env, mu, server, provider):\n",
    "    global total_requests_1, total_requests_2\n",
    "    while True:\n",
    "        yield env.timeout(random.expovariate(LAMBDA))\n",
    "        if provider == 1:\n",
    "            total_requests_1 += 1\n",
    "            env.process(request(env, mu, server, provider))\n",
    "        elif provider == 2:\n",
    "            total_requests_2 += 1\n",
    "            env.process(request(env, mu, server, provider))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = simpy.Environment()\n",
    "server_1 = simpy.Resource(env, capacity=1)\n",
    "server_2 = simpy.Resource(env, capacity=SERVERS_2)  # Asumimos 10 servidores\n",
    "\n",
    "env.process(request_generator(env, MU_1, server_1, 1))  # El 1 al final indica Proveedor 1\n",
    "env.process(request_generator(env, MU_2, server_2, 2))  # El 2 al final indica Proveedor 2\n",
    "\n",
    "env.run(until=SIMULATION_TIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solicitudes totales atendidas por el Proveedor 1: 143526\n",
      "Solicitudes totales atendidas por el Proveedor 2: 144336\n",
      "Tiempo total de servicio del Proveedor 1: 2397.51 segundos\n",
      "Tiempo total de servicio del Proveedor 2: 14484.38 segundos\n",
      "Tiempo total desocupado para el Proveedor 1: 1202.49 segundos\n",
      "Tiempo total desocupado para el Proveedor 2: -10884.38 segundos\n",
      "Tiempo total en cola para el Proveedor 1: 958.68 segundos\n",
      "Tiempo total en cola para el Proveedor 2: 22.25 segundos\n",
      "Tiempo promedio en cola para el Proveedor 1: 0.01 segundos\n",
      "Tiempo promedio en cola para el Proveedor 2: 0.00 segundos\n",
      "Número promedio de solicitudes en cola por segundo para el Proveedor 1: 0.27\n",
      "Número promedio de solicitudes en cola por segundo para el Proveedor 2: 0.01\n"
     ]
    }
   ],
   "source": [
    "# Al finalizar la simulación, calculamos y mostramos estadísticas\n",
    "idle_time_1 = SIMULATION_TIME - total_time_of_service_1\n",
    "idle_time_2 = SIMULATION_TIME - total_time_of_service_2\n",
    "\n",
    "# a. ¿Cuántas solicitudes atendió cada servidor?\n",
    "print(f\"Solicitudes totales atendidas por el Proveedor 1: {total_requests_1}\")\n",
    "print(f\"Solicitudes totales atendidas por el Proveedor 2: {total_requests_2}\")\n",
    "\n",
    "# b. ¿Cuánto tiempo estuvo cada servidor ocupado?\n",
    "print(f\"Tiempo total de servicio del Proveedor 1: {total_time_of_service_1:.2f} segundos\")\n",
    "print(f\"Tiempo total de servicio del Proveedor 2: {total_time_of_service_2:.2f} segundos\")\n",
    "\n",
    "# c. ¿Cuánto tiempo estuvo cada servidor desocupado (idle)?\n",
    "print(f\"Tiempo total desocupado para el Proveedor 1: {idle_time_1:.2f} segundos\")\n",
    "print(f\"Tiempo total desocupado para el Proveedor 2: {idle_time_2:.2f} segundos\")\n",
    "\n",
    "# d. ¿Cuánto tiempo en total estuvieron las solicitudes en cola?\n",
    "print(f\"Tiempo total en cola para el Proveedor 1: {total_time_in_queue_1:.2f} segundos\")\n",
    "print(f\"Tiempo total en cola para el Proveedor 2: {total_time_in_queue_2:.2f} segundos\")\n",
    "\n",
    "# e. En promedio, ¿cuánto tiempo estuvo cada solicitud en cola?\n",
    "print(f\"Tiempo promedio en cola para el Proveedor 1: {total_time_in_queue_1/total_requests_1:.2f} segundos\")\n",
    "print(f\"Tiempo promedio en cola para el Proveedor 2: {total_time_in_queue_2/total_requests_2:.2f} segundos\")\n",
    "\n",
    "# f. En promedio, ¿cuántas solicitudes estuvieron en cola cada segundo?\n",
    "print(f\"Número promedio de solicitudes en cola por segundo para el Proveedor 1: {total_time_in_queue_1/SIMULATION_TIME:.2f}\")\n",
    "print(f\"Número promedio de solicitudes en cola por segundo para el Proveedor 2: {total_time_in_queue_2/SIMULATION_TIME:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de servidores requeridos para evitar la espera en cola: 10\n"
     ]
    }
   ],
   "source": [
    "env = simpy.Environment()\n",
    "server_2 = simpy.Resource(env, capacity=SERVERS_2)\n",
    "\n",
    "env.process(request_generator(env, MU_2, server_2, 2))\n",
    "\n",
    "# Ejecute la simulación\n",
    "env.run(until=SIMULATION_TIME)\n",
    "\n",
    "print(f\"Número de servidores requeridos para evitar la espera en cola: {SERVERS_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solicitudes totales atendidas por el Proveedor 1: 359437\n",
      "Solicitudes totales atendidas por el Proveedor 2: 359980\n",
      "Tiempo total de servicio del Proveedor 1: 958558.34 segundos\n",
      "Tiempo total de servicio del Proveedor 2: 986860.17 segundos\n",
      "Tiempo total desocupado para el Proveedor 1: -954958.34 segundos\n",
      "Tiempo total desocupado para el Proveedor 2: -983260.17 segundos\n",
      "Tiempo total en cola para el Proveedor 1: 954969.37 segundos\n",
      "Tiempo total en cola para el Proveedor 2: 950954.29 segundos\n",
      "Tiempo promedio en cola para el Proveedor 1: 2.66 segundos\n",
      "Tiempo promedio en cola para el Proveedor 2: 2.64 segundos\n",
      "Número promedio de solicitudes en cola por segundo para el Proveedor 1: 265.27\n",
      "Número promedio de solicitudes en cola por segundo para el Proveedor 2: 264.15\n",
      "\n",
      "\n",
      "Número de servidores requeridos para evitar la espera en cola: 10\n"
     ]
    }
   ],
   "source": [
    "# Tasa de solicitudes por segundo\n",
    "LAMBDA = 6000 / 60  # Convertimos las solicitudes por minuto a solicitudes por segundo\n",
    "\n",
    "# Duración de la simulación en segundos (1 hora)\n",
    "SIMULATION_TIME = 3600  \n",
    "\n",
    "# Proveedor 1\n",
    "MU_1 = 100  # Tasa de servicio de 100 solicitudes por segundo\n",
    "\n",
    "# Proveedor 2\n",
    "MU_2 = 10    # Tasa de servicio de 10 solicitudes por segundo\n",
    "SERVERS_2 = 10  # Número de servidores\n",
    "\n",
    "# Variables para estadísticas para Proveedor 1 y Proveedor 2\n",
    "total_requests_1 = total_requests_2 = 0\n",
    "total_time_in_queue_1 = total_time_in_queue_2 = 0\n",
    "total_time_of_service_1 = total_time_of_service_2 = 0\n",
    "\n",
    "env = simpy.Environment()\n",
    "server_1 = simpy.Resource(env, capacity=1)\n",
    "server_2 = simpy.Resource(env, capacity=SERVERS_2)  # Asumimos 10 servidores\n",
    "\n",
    "env.process(request_generator(env, MU_1, server_1, 1))  # El 1 al final indica Proveedor 1\n",
    "env.process(request_generator(env, MU_2, server_2, 2))  # El 2 al final indica Proveedor 2\n",
    "\n",
    "env.run(until=SIMULATION_TIME)\n",
    "\n",
    "# Al finalizar la simulación, calculamos y mostramos estadísticas\n",
    "idle_time_1 = SIMULATION_TIME - total_time_of_service_1\n",
    "idle_time_2 = SIMULATION_TIME - total_time_of_service_2\n",
    "\n",
    "# a. ¿Cuántas solicitudes atendió cada servidor?\n",
    "print(f\"Solicitudes totales atendidas por el Proveedor 1: {total_requests_1}\")\n",
    "print(f\"Solicitudes totales atendidas por el Proveedor 2: {total_requests_2}\")\n",
    "\n",
    "# b. ¿Cuánto tiempo estuvo cada servidor ocupado?\n",
    "print(f\"Tiempo total de servicio del Proveedor 1: {total_time_of_service_1:.2f} segundos\")\n",
    "print(f\"Tiempo total de servicio del Proveedor 2: {total_time_of_service_2:.2f} segundos\")\n",
    "\n",
    "# c. ¿Cuánto tiempo estuvo cada servidor desocupado (idle)?\n",
    "print(f\"Tiempo total desocupado para el Proveedor 1: {idle_time_1:.2f} segundos\")\n",
    "print(f\"Tiempo total desocupado para el Proveedor 2: {idle_time_2:.2f} segundos\")\n",
    "\n",
    "# d. ¿Cuánto tiempo en total estuvieron las solicitudes en cola?\n",
    "print(f\"Tiempo total en cola para el Proveedor 1: {total_time_in_queue_1:.2f} segundos\")\n",
    "print(f\"Tiempo total en cola para el Proveedor 2: {total_time_in_queue_2:.2f} segundos\")\n",
    "\n",
    "# e. En promedio, ¿cuánto tiempo estuvo cada solicitud en cola?\n",
    "print(f\"Tiempo promedio en cola para el Proveedor 1: {total_time_in_queue_1/total_requests_1:.2f} segundos\")\n",
    "print(f\"Tiempo promedio en cola para el Proveedor 2: {total_time_in_queue_2/total_requests_2:.2f} segundos\")\n",
    "\n",
    "# f. En promedio, ¿cuántas solicitudes estuvieron en cola cada segundo?\n",
    "print(f\"Número promedio de solicitudes en cola por segundo para el Proveedor 1: {total_time_in_queue_1/SIMULATION_TIME:.2f}\")\n",
    "print(f\"Número promedio de solicitudes en cola por segundo para el Proveedor 2: {total_time_in_queue_2/SIMULATION_TIME:.2f}\")\n",
    "\n",
    "\n",
    "env = simpy.Environment()\n",
    "server_2 = simpy.Resource(env, capacity=SERVERS_2)\n",
    "\n",
    "env.process(request_generator(env, MU_2, server_2, 2))\n",
    "\n",
    "# Ejecute la simulación\n",
    "env.run(until=SIMULATION_TIME)\n",
    "\n",
    "print(f\"\\n\\nNúmero de servidores requeridos para evitar la espera en cola: {SERVERS_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4\n",
    "\n",
    "1. Capacidad de Atencion\n",
    "    * En el escenario inicial de 2400 solicitudes por nminuto ambos proveedores pueden manejar la carga de trabajo sin mayor complicaciones\n",
    "    * Sin embargo, con un aumento a 6,000 solicitudes por minuto, aunque ambos proveedores pudieron atender todas las solicitudes, la cantidad de tiempo que las solicitudes pasaron en cola fue significativamente alta, lo que indica un posible retraso en la atención al usuario.\n",
    "\n",
    "2. Tiempos de Cola\n",
    "    * En el escenario de 6,000 solicitudes por minuto, el tiempo promedio en cola fue de aproximadamente 2.65 segundos para el Proveedor 1 y 2.64 segundos para el Proveedor 2. Esto puede ser una espera inaceptablemente larga para los usuarios y puede afectar negativamente la experiencia del usuario. Por loq ue se deberian buscar que los proveedores nos den mas servidores para que se puedan atender mas llamadas,\n",
    "\n",
    "3. Desempeño de Servidores:\n",
    "\n",
    "    * El Proveedor 1, con su servidor único pero potente, tuvo menos tiempo en cola en el escenario inicial, pero su desempeño se deterioró con la carga incrementada.\n",
    "    * El Proveedor 2, con múltiples servidores, mostró una mejor distribución de la carga, especialmente en el escenario de alta carga.\n",
    "\n",
    "4. Tiempo Desocupado:\n",
    "\n",
    "    * En el escenario de alta carga, ambos proveedores mostraron un tiempo desocupado negativo, lo cual es un indicador de que los servidores estuvieron sobrecargados durante la simulación.\n",
    "\n",
    "5. Flexibilidad:\n",
    "\n",
    "    * El modelo de múltiples servidores del Proveedor 2 ofrece una mayor flexibilidad, ya que se puede escalar el número de servidores según la demanda. Esto puede ser especialmente beneficioso a medida que la aplicación crece en usuarios y tráfico.\n",
    "\n",
    "\n",
    "6. Recomendación Final:\n",
    "\n",
    "    * Se recomienda considerar el Proveedor 2 (Pizzita computing) debido a su flexibilidad para escalar y su desempeño relativamente mejor en escenarios de alta carga.\n",
    "    * Sería prudente también explorar con cada proveedor las opciones para optimizar la configuración del servidor y mejorar el desempeño, especialmente en condiciones de alta carga.\n",
    "    * Además, se recomienda tener una discusión detallada sobre los costos con ambos proveedores para tomar una decisión informada que también sea económicamente viable para el proyecto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
